---
layout: single
title: "쿠버네티스  모니터링 설치"
categories: linux
tags: [linux, container, kubernetes , 인강-일프로, 쿠버네티스 어나더 클래스 (지상편) - Sprint 1 2 , monitoring, promethus, grafana, loki  ]
toc: true
---

# Github에서 Promethus, Grafana 설치
출처:https://cafe.naver.com/kubeops
## 설치 

~~~
#git 설치
[root@k8s-master ~]# yum -y install git

# 로컬 저장소 생성
git init monitoring
git config --global init.defaultBranch main
cd monitoring

# remote 추가 ([root@k8s-master monitoring]#)
git remote add -f origin https://github.com/k8s-1pro/install.git

# sparse checkout 설정
git config core.sparseCheckout true
echo "ground/k8s-1.27/prometheus-2.44.0" >> .git/info/sparse-checkout
echo "ground/k8s-1.27/loki-stack-2.6.1" >> .git/info/sparse-checkout

# 다운로드 
git pull origin main
~~~

## Promethus (with Grafana) 설치
~~~
# 설치 ([root@k8s-master monitoring]#)
kubectl apply --server-side -f ground/k8s-1.27/prometheus-2.44.0/manifests/setup
kubectl wait --for condition=Established --all CustomResourceDefinition --namespace=monitoring
kubectl apply -f ground/k8s-1.27/prometheus-2.44.0/manifests

# 설치 확인 ([root@k8s-master]#) 
kubectl get pods -n monitoring
~~~

![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory9.png)


## Loki 설치 
~~~

# 설치 ([root@k8s-master monitoring]#)
kubectl apply -f ground/k8s-1.27/loki-stack-2.6.1

# 설치 확인
kubectl get pods -n loki-stack
~~~
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory10.png)


## Grafana 접속

~~~
[4] Grafana 접속

▶ 접속 URL : http://192.168.56.30:30001

▶ 로그인 :​ id: admin, pw: admin

▶ 확인 결과 
~~~

## Grafana 에 Loki 연동
Connect data : Home > Connections > Connect data
검색에 [loki] 입력 후 항목 클릭
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory11.png)
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory12.png)


## Loki 앱 로그보기 
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory15.png)
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory16.png)
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory17.png)




### 연동 후 테스트
예제 코드
~~~
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-1-2-2-1
spec:
  selector:
    matchLabels:
      app: '1.2.2.1'
  replicas: 2
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: '1.2.2.1'
    spec:
      containers:
        - name: app-1-2-2-1
          image: 1pro/app
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
          startupProbe:
            httpGet:
              path: "/ready"
              port: http
            failureThreshold: 10
          livenessProbe:
            httpGet:
              path: "/ready"
              port: http
          readinessProbe:
            httpGet:
              path: "/ready"
              port: http
          resources:
            requests:
              memory: "100Mi"
              cpu: "100m"
            limits:
              memory: "200Mi"
              cpu: "200m"
---
apiVersion: v1
kind: Service
metadata:
  name: app-1-2-2-1
spec:
  selector:
    app: '1.2.2.1'
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 31221
  type: NodePort
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-1-2-2-1
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app-1-2-2-1
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 40
~~~

### 트래픽 보내기 
~~~
[root@k8s-master ~]# while true; do curl http://192.168.56.30:31221/hostname; sleep 2; echo '';  done;
~~~
트래픽 분산 관련 자료 : https://kubernetes.io/ko/docs/reference/networking/virtual-ips/

### 메모리 leak 테스트
~~~
[root@k8s-master ~]# curl 192.168.56.30:31221/memory-leak
~~~

### 부하주기
~~~
[root@k8s-master ~]# curl 192.168.56.30:31221/cpu-load
~~~

### 이미지 업데이트
~~~
[root@k8s-master ~]# kubectl set image -n default deployment/app-1-2-2-1 app-1-2-2-1=1pro/app-update
~~~

###  기동되지 않는 App 업데이트 (RollingUpdate 테스트)
~~~
[root@k8s-master ~]# kubectl set image -n default deployment/app-1-2-2-1 app-1-2-2-1=1pro/app-error
~~~

###  업데이트 중지하고 롤백 할 경우
~~~
[root@k8s-master ~]# kubectl rollout undo -n default deployment/app-1-2-2-1
~~~



# 삭제
~~~
[root@k8s-master ~]# cd monitoring

# Prometheus 삭제
kubectl delete --ignore-not-found=true -f ground/k8s-1.27/prometheus-2.44.0/manifests -f ground/k8s-1.27/prometheus-2.44.0/manifests/setup

# Loki-stack 삭제
kubectl delete -f ground/k8s-1.27/loki-stack-2.6.1
~~~






# 발생 이슈
## 1. error getting ClusterInformation: connection is unauthorized: Unauthorized

이 내용은 Calico를 cni로 사용하면 발생한며, Calico 를 재설치 해줘야한다.
filedCreatePodSandBox 요류
[https://www.containiq.com/post/troubleshooting-failed-to-create-pod-sandbox-error]


## 2. Grafana " No data " 상태 나타나는 현상
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory13.png)

- 원인
![출처:https://cafe.naver.com/kubeops](/Images/인강/linuxhistory14.png)
System clock synchronized: no 라서 발생


- 해결방법
~~~
systemctl restart chronyd.service
~~~
